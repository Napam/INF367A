{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re, random\n",
    "from scipy.stats import beta, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We draw with replacement from a bucket of black and white balls.  The parameter $\\theta_b$ is the probability of drawing a black ball, and $\\theta_w$ is the probability of a white ball: $P(b|\\theta_b,\\theta_w) = \\theta_b$ and $P(w|\\theta_b,\\theta_w) = \\theta_w = 1 - \\theta_b$. $$$$\n",
    "\n",
    "We draw $n$ balls from the bucket. What is our estimate of $\\theta_b$? $$$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Independent and identically distributed (i.i.d)\n",
    "\n",
    "- If the data generating mechanism depends on $\\theta$ only (and not on what has been generated before), the sequence of data is called independent and identically distributed.\n",
    "- Then \n",
    "\\begin{eqnarray*}\n",
    " P(d_1, d_2, \\ldots, d_n|\\theta) = \\prod_{i=1}^{n} P(d_i|\\theta).\n",
    "\\end{eqnarray*}\n",
    "- And order of $d_i$ doesn't matter:\n",
    "\\begin{eqnarray*}\n",
    " P(b, w, b, b, w\\mid \\theta) & = & P(b, b, b, w, w |\\theta)\\\\\n",
    " & = & P(b|\\theta)  P(b|\\theta)  P(b|\\theta)  P(w|\\theta)  P(w|\\theta). \n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli model\n",
    "\n",
    "- A model for i.i.d. binary outcomes: (heads, tails), (black, white), (0, 1), (true, false),...\n",
    "- One parameter: $\\theta\\in [0, 1]$. For example, $ P(d = true\\mid \\theta) = \\theta $, $ P(d = false\\mid \\theta) = 1-\\theta $.$$$$\n",
    "- Note that the probabilities of $d$ being true are **determined by** $\\theta$. Parameters are not probabilities.$$$$\n",
    "- As the parameter $\\theta$ determines a unique model, we call also the model as $\\theta$.$$$$ \n",
    "- Easy to show that $E[d] =\\theta$ and $\\textrm{var}[d] = \\theta (1-\\theta)$.$$$$\n",
    "- Black and white ball bucket as a Bernoulli model:\n",
    " - $\\theta$ is the proportion of the black balls in a bucket, $P(b\\mid \\theta) = \\theta$.$$$$\n",
    " - **Likelihood:** $P(D\\mid\\theta) = \\theta^{N_b} (1 - \\theta)^{N_w}$, where $N_b$ and $N_w$ are the numbers of black and white balls in the data $D$, respectively.$$$$\n",
    " - Note that $P(D\\mid\\theta)$ depends on the data $D$ through $N_b$ and $N_w$ only (= sufficient statistics).$$$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(D, theta):\n",
    "    n_w = len(re.findall('w', D))\n",
    "    n_b = len(re.findall('b', D))\n",
    "    return theta**n_b*(1-theta)**n_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe data\n",
    "D = 'wbbbwbbbw'\n",
    "n_w = len(re.findall('w', D))\n",
    "n_b = len(re.findall('b', D))\n",
    "\n",
    "# Plot the likelihood as a function of theta\n",
    "t = np.linspace(0, 1, 100)\n",
    "y = likelihood(D, t)\n",
    "\n",
    "plt.plot(t, y)\n",
    "plt.title('Likelihood')\n",
    "plt.ylabel('P(D|theta)')\n",
    "plt.xlabel('$theta$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Likelihood is a function of $\\theta$. Thus, the area under the curve is not necessarily $1$$$$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood parameters for the Bernoulli model\n",
    " \n",
    "- Let us find Maximum likelihood (ML) parameters for the Bernoulli model for the data with $N_b$ black balls and $N_w$ white ones.$$$$\n",
    "- Likelihood: $P(D\\mid\\theta) = \\theta^{N_b}(1-\\theta)^{N_w}$.\n",
    "- Let us check when $P'(D\\mid\\theta) = 0$, $\\theta \\in ]0, 1[$:\n",
    "  \\begin{eqnarray*}\n",
    "  P'(D\\mid\\theta) & = & N_b \\theta^{N_b - 1}(1 - \\theta)^{N_w} + \\theta^{N_b} N_{w} (1 - \\theta)^{N_w - 1}(-1)\\\\\n",
    "   & = & \\theta^{N_b -1}(1-\\theta)^{N_w - 1}[N_b(1 - \\theta) -\\theta N_w]\\\\\n",
    "   & = & \\theta^{N_b -1}(1-\\theta)^{N_w - 1}[N_b - (N_b + N_w)\\theta] = 0\\\\\n",
    "   & \\Leftrightarrow & N_b - (N_b + N_w)\\theta = 0\\\\\n",
    "   & \\Leftrightarrow & \\theta = \\frac{N_b}{N_b + N_w}.\n",
    "  \\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem with maximum likelihood\n",
    "D_prime = 'ww'\n",
    "n_w_prime = len(re.findall('w', D_prime))\n",
    "n_b_prime = len(re.findall('b', D_prime))\n",
    "\n",
    "theta_ml = n_b_prime/(n_b_prime + n_w_prime)\n",
    "\n",
    "print('theta_ml = %s' % theta_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A possible prior\n",
    "\n",
    "We can discretise the range of $\\theta_b$ and consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_values = np.linspace(0, 1, 11)\n",
    "prior_p = [0.05, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05]\n",
    "#prior_p = [0, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.15, 0.05, 0]\n",
    "\n",
    "assert(len(theta_values) == len(prior_p))\n",
    "assert(np.sum(prior_p) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=theta_values, height=prior_p, width=0.05)\n",
    "plt.title('Prior')\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('p')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute posterior\n",
    "posterior_unnormalized = prior_p*likelihood(D, theta_values) # Joint probability\n",
    "evidence = np.sum(posterior_unnormalized)\n",
    "posterior = posterior_unnormalized/evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posterior\n",
    "plt.bar(x=theta_values, height=posterior, width=0.05)\n",
    "plt.title('Posterior')\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('p')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta distribution\n",
    "\n",
    "- The density is in form $P(\\theta) = c \\theta^{\\alpha - 1}(1 -\\theta)^{\\beta - 1}$, where the normalization constant is \n",
    "  \\begin{eqnarray*}\n",
    "   c & = & \\frac{1}{\\int_{0}^{1} \\theta^{\\alpha - 1}(1 -\\theta)^{\\beta - 1} \\mathrm{d} \\theta}\\\\\n",
    "   & = & \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)},\n",
    "  \\end{eqnarray*}\n",
    "  where $\\Gamma$ is the gamma function, a continuous version of the factorial: $\\Gamma(n) = (n -1)!$.\n",
    "- Mean = $\\frac{\\alpha}{\\alpha + \\beta}$, mode = $\\frac{\\alpha - 1}{\\alpha + \\beta- 2}$ (for $\\alpha>1, \\beta>1$)$$$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the beta distribution with different parameter values\n",
    "aa = [0.5, 1, 1, 2, 3, 10, 1.5, 7]\n",
    "bb = [0.5, 1, 2, 2, 5 ,3, 12, 1]\n",
    "x = np.linspace(0, 1, 101)\n",
    "\n",
    "for i in range(len(aa)):\n",
    "    a = aa[i]\n",
    "    b = bb[i]\n",
    "    dist = beta(a, b)\n",
    "    y = dist.pdf(x)\n",
    "    plt.plot(x,y)\n",
    "    plt.title('Beta(%s, %s)' % (a, b))\n",
    "    plt.xlabel('theta')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a beta prior\n",
    "a_prior = 7\n",
    "b_prior = 1\n",
    "\n",
    "prior2 = beta(a_prior, b_prior)\n",
    "\n",
    "x = np.linspace(0, 1, 101)\n",
    "y = prior2.pdf(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('Prior: Beta(%s, %s)' % (a_prior, b_prior))\n",
    "plt.xlabel('theta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior with beta prior\n",
    "\n",
    "- The forms of the likelihood and the prior seem comfortable\n",
    " - $P(D\\mid\\theta) = \\theta^{N_b}(1 -\\theta)^{N_w}$\n",
    " - We define the prior $P(\\theta) = c \\theta^{\\alpha - 1}(1 -\\theta)^{\\beta - 1}$, where the normalization constant $c$ takes care that $\\int P(\\theta)\\mathrm{d}\\theta = 1$.$$$$\n",
    " - Then $P(D\\mid\\theta) P(\\theta) = c \\theta^{N_b + \\alpha - 1}(1 -\\theta)^{N_w + \\beta - 1}$$$$$\n",
    "- Thus updating from prior to posterior is easy: just use the formula for the prior, and update exponents $\\alpha - 1$ and $\\beta - 1$ (conjugate prior).$$$$\n",
    "- $\\alpha$ and $\\beta$ are parameters of the prior distribution, i.e., hyperparameters.$$$$\n",
    "- \\begin{eqnarray*}\n",
    " P(\\theta\\mid D, \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + N_b + \\beta + N_w)}{\\Gamma(\\alpha + N_b)\\Gamma(\\beta + N_w)} \\theta^{\\alpha + N_b -1} (1 - \\theta)^{\\beta + N_w - 1}\n",
    "\\end{eqnarray*}\n",
    "- Thus, a posteriori, $\\theta_b$ is distributed by $\\mathrm{Beta}(\\alpha + N_b$, $\\beta + N_w)$ $$$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot the posterior\n",
    "show_point_estimates = False\n",
    "\n",
    "a_posterior = a_prior + n_b\n",
    "b_posterior = b_prior + n_w\n",
    "\n",
    "posterior2 = beta(a_posterior, b_posterior)\n",
    "\n",
    "x = np.linspace(0, 1, 101)\n",
    "y = posterior2.pdf(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('Posterior: Beta(%s, %s)' % (a_posterior, b_posterior))\n",
    "plt.xlabel('theta')\n",
    "\n",
    "if show_point_estimates:\n",
    "    plt.plot([theta_map, theta_map], [0, posterior2.pdf(theta_map)], c='r', label='MAP')\n",
    "    plt.plot([theta_ml, theta_ml], [0, posterior2.pdf(theta_ml)], c='m', label='ML')\n",
    "    plt.plot([theta_mean, theta_mean], [0, posterior2.pdf(theta_mean)], c='c', label='Mean')\n",
    "\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian updating\n",
    "\n",
    "- Start with a prior with hyperparameters $\\alpha$ and $\\beta$. Now $\\theta \\sim \\mathrm{Beta}(\\alpha, \\beta)$.$$$$\n",
    "- Observe data with $N_w$ white balls and $N_b$ black ones. A posteriori   $\\theta \\sim \\mathrm{Beta}(N_b + \\alpha, N_w + \\beta)$.$$$$\n",
    "- We observe another data, now with $N_{w}' $ white balls and $N_b'$ black ones. We use the posteriori distribution  obtained earlier as our prior. Now the updated posteriori is  $\\theta \\sim \\mathrm{Beta}(N_b + N_b' + \\alpha, N_w + N_w' + \\beta)$.$$$$\n",
    "- This is equivalent to combining the two small datasets into a big one.\n",
    "- An advantage of sequential Bayesian updating is that you can learn online and you don't need to store the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = 'wbbwwww'\n",
    "D2 = 'bbwwbbw'\n",
    "D = D1 + D2\n",
    "\n",
    "n_w1 = len(re.findall('w', D1))\n",
    "n_b1 = len(re.findall('b', D1))\n",
    "n_w2 = len(re.findall('w', D2))\n",
    "n_b2 = len(re.findall('b', D2))\n",
    "n_w = len(re.findall('w', D))\n",
    "n_b = len(re.findall('b', D))\n",
    "\n",
    "\n",
    "x = np.linspace(0, 1, 101)\n",
    "\n",
    "f_prior = beta.pdf(x, a=a_prior, b=b_prior)\n",
    "a_posterior1 = a_prior+n_w1\n",
    "b_posterior1 = b_prior+n_b1\n",
    "f1 = beta.pdf(x, a=a_posterior1, b=b_posterior1)\n",
    "a_posterior2 = a_posterior1 + n_w2\n",
    "b_posterior2 = b_posterior1 + n_b2\n",
    "f2 = beta.pdf(x, a=a_posterior2, b=b_posterior2)\n",
    "a_posterior = a_prior + n_w\n",
    "b_posterior = b_prior + n_b\n",
    "f = beta.pdf(x, a=a_posterior, b=b_posterior)\n",
    "\n",
    "plt.plot(x, f_prior, label='Prior')\n",
    "plt.plot(x, f1, label='Posterior after observing D1')\n",
    "plt.plot(x, f2, label='Posterior after observing D1 and D2')\n",
    "plt.plot(x, f, label='Posterior after observing D')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_true = 0.7\n",
    "ns = [0, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "x = np.linspace(0, 1, 101)\n",
    "\n",
    "# Priors\n",
    "a_priors = [1, 1, 10]\n",
    "b_priors = [1, 5, 3]\n",
    "\n",
    "for n in ns:\n",
    "    D = ''.join(random.choices(['b', 'w'], weights=[theta_true, 1-theta_true], k=n))\n",
    "    n_w = len(re.findall('w', D))\n",
    "    n_b = len(re.findall('b', D))\n",
    "    for i in range(len(a_priors)):\n",
    "        f = beta.pdf(x, a=a_priors[i] + n_b, b=b_priors[i] + n_w)\n",
    "        plt.plot(x, f, label='Prior: Beta(%s, %s)' % (a_priors[i], b_priors[i]))\n",
    "    if n > 0:\n",
    "        plt.title('Posteriors after %s observations' % n)\n",
    "    else:\n",
    "        plt.title('Priors')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive distribution\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "  P(b\\mid D, \\alpha, \\beta) & = & \\int_{0}^{1} P(b\\mid \\theta, D, \\alpha, \\beta) P(\\theta\\mid D, \\alpha, \\beta)\\mathrm{d} \\theta\\\\\n",
    "  & = & \\int_{0}^{1} P(b\\mid \\theta) P(\\theta\\mid D, \\alpha, \\beta)\\mathrm{d} \\theta\\\\\n",
    "  & = & \\int_{0}^{1} \\theta P(\\theta\\mid D, \\alpha, \\beta)\\mathrm{d} \\theta\\\\\n",
    "  & = & E_P (\\theta)\\\\\n",
    "  & = & \\frac{\\alpha + N_b}{\\alpha + N_b + \\beta + N_w}.\n",
    " \\end{eqnarray*} \n",
    "- Sounds rational.\n",
    "- Notice how the hyperparameters $\\alpha$ and $\\beta$ act like extra counts (pseudocounts).$$$$\n",
    "- Predictive probabilities change less radically when $\\alpha + \\beta$ is large\n",
    "- Interpretation: before formulation the prior, one has experience of previous observations - thus with $\\alpha + \\beta$ one can indicate confidence measured in observations\n",
    "- Called \"equivalent sample size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = a_posterior/(a_posterior + b_posterior)\n",
    "print('Prediction: probability of observing a black ball = %s' % pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evidence accumulates, our beliefs converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarising posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posteriorSummaries(a_prior, b_prior, n_b, n_w):\n",
    "    theta_map = (a_prior + n_b - 1)/(a_prior + b_prior + n_b + n_w - 2)\n",
    "    theta_mean = (a_prior + n_b)/(a_prior + b_prior + n_b + n_w)\n",
    "    theta_ml = n_b/(n_b + n_w)\n",
    "    return theta_map, theta_mean, theta_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -2.7\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return pi1*dist1.pdf(x) + pi2*dist2.pdf(x) + pi3*dist3.pdf(x)\n",
    "\n",
    "mu1 = 0\n",
    "sigma1 = np.sqrt(1)\n",
    "dist1 = norm(mu1, sigma1)\n",
    "\n",
    "mu2 = 5\n",
    "sigma2 = np.sqrt(0.005)\n",
    "dist2 = norm(mu2, sigma2)\n",
    "\n",
    "mu3 = -8\n",
    "sigma3 = np.sqrt(1)\n",
    "dist3 = norm(mu3, sigma3)\n",
    "\n",
    "pi1 = 0.5\n",
    "pi2 = 0.1\n",
    "pi3 = 1 - pi1 - pi2\n",
    "\n",
    "x = np.linspace(-12, 8, 200)\n",
    "y = f(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "\n",
    "map_ind = np.argmax(y)\n",
    "plt.plot([x[map_ind], x[map_ind]], [0, y[map_ind]], c='m', label='MAP')\n",
    "\n",
    "m = pi1*mu1 + pi2*mu2 + pi3*mu3\n",
    "plt.plot([m, m], [0, f(m)], c='r', label='Mean')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Mean: %s' % m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
