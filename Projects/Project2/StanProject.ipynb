{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 42069\n",
    "np.random.seed(seed)\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import arviz\n",
    "import pystan\n",
    "from scipy import sparse, stats\n",
    "from typing import Iterable, Union, Callable\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "import altair as alt\n",
    "from time import time, sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Own files\n",
    "import utils \n",
    "import StanClasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have is essentially a matrix, where the each row correspond to a person, and each column correspond to a movie. However, the matrix is very sparse and thus data is stored in sparse format (i.e. specified with indices and the corresponding values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "DATA_DIR = 'ml-100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _, _ = utils.get_ml100k_data(DATA_DIR, subsample_top_users=150, subsample_top_items=20)\n",
    "df[['user_id', 'item_id']] -= 1\n",
    "\n",
    "# We are not going to use timestamp, therefore drop it\n",
    "df.drop('timestamp', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user ids and item (movie) ids are essentially integer ranges, starting from and 1 to the number of users and items respectively. We don't have the all the unique ids when subsampling users and movies. It becomes problematic ... TODO: Write this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_relabler(df: pd.DataFrame, column: str):\n",
    "    uniques = pd.value_counts(df[column], sort=False).index.values\n",
    "    n_uniques = len(uniques)\n",
    "\n",
    "    # Count from 1 to conform with Stan (Stan counts indexes arrays starting at 1)\n",
    "    num2id = {num_:id_ for num_, id_ in zip(range(0, n_uniques), uniques)}\n",
    "    id2num = {id_:num_ for num_, id_ in zip(range(0, n_uniques), uniques)}\n",
    "    \n",
    "    df[column] = df[column].map(id2num)\n",
    "    return id2num, num2id\n",
    "\n",
    "df_num = df.copy()\n",
    "user2num, num2user = column_relabler(df_num, 'user_id')\n",
    "item2num, num2item = column_relabler(df_num, 'item_id')\n",
    "\n",
    "# p, q represents shape of the matrix as if it was dense\n",
    "p, q = len(user2num), len(item2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valtest = train_test_split(df_num, test_size=0.1)\n",
    "df_val, df_test = train_test_split(df_valtest, test_size=0.5)\n",
    "del df_valtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization \n",
    "Want to factorize the dense matrix $X_{n\\times m} \\approx U_{n\\times k}V_{k\\times m}$, where the subscripts denotes matrix shapes. The $k$ dimension denotes the user specified embedding dimension. We use different probabilistic models for the components. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Simple\n",
    "Ultra simple\n",
    "\n",
    "$$ U_{ij} \\sim N(\\mu_u, \\sigma_u) $$\n",
    "$$ V_{ij} \\sim N(\\mu_v, \\sigma_v) $$\n",
    "$$ X_{ij}\\sim N((UV_{ij}), \\sigma_x)$$\n",
    "\n",
    "User defined variables:\n",
    "$\\mu_u, \\sigma_u, \\mu_v, \\sigma_v, \\sigma_x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Non-negative Matrix Factorization\n",
    "\n",
    "$$ U_{ij}\\sim Gamma(a_u, b_u) $$\n",
    "$$ V_{ij}\\sim Gamma(a_v, b_v) $$\n",
    "$$ X_{ij}\\sim Normal(UV_{ij}, \\beta)$$\n",
    "$$ \\beta \\sim Gamma(a_\\beta, b_\\beta) $$\n",
    "\n",
    "User defined variables:\n",
    "$a_u, b_u, a_v, b_v, a_\\beta, b_\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: ARD\n",
    "\n",
    "$$ U_{ij} \\sim N(\\mu_u, \\alpha_j) $$\n",
    "$$ V_{ij} \\sim N(\\mu_v, \\alpha_j) $$\n",
    "$$ X_{ij}\\sim N((UV)_{ij}, \\beta)$$\n",
    "$$ \\beta \\sim Gamma(a_\\beta, b_\\beta) $$\n",
    "\n",
    "$$ \\alpha_{ij} \\sim Gamma(a_\\alpha, b_\\alpha) $$\n",
    "\n",
    "User defined variables:\n",
    "$\\mu_u, \\mu_v, a_\\alpha, b_\\alpha, a_\\beta, b_\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2K samples, 1 chain, 5 thin\n",
    "\n",
    "X_hat:            2min 30s, 2min 35, 2min 23s\n",
    "\n",
    "Array of vectors: 4min 21s, 4min 19s\n",
    "\n",
    "Matrix, no X_hat: 6min 14s, 6min 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models:   0%|          | 0/12 [00:00<?, ?model/s]WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "Fitting models:   8%|▊         | 1/12 [01:15<13:52, 75.66s/model]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel\n",
      "Using cached StanModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "Fitting models:  17%|█▋        | 2/12 [03:01<14:07, 84.72s/model]WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "Fitting models:  25%|██▌       | 3/12 [05:06<14:31, 96.82s/model]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel\n",
      "Using cached StanModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "Fitting models:  33%|███▎      | 4/12 [07:51<15:38, 117.37s/model]WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "Fitting models:  42%|████▏     | 5/12 [08:20<10:35, 90.80s/model] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel\n",
      "Using cached StanModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "Fitting models:  50%|█████     | 6/12 [09:23<08:14, 82.41s/model]WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "Fitting models:  58%|█████▊    | 7/12 [10:42<06:46, 81.32s/model]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel\n",
      "Using cached StanModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "Fitting models:  67%|██████▋   | 8/12 [12:10<05:34, 83.53s/model]WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "Fitting models:  75%|███████▌  | 9/12 [13:32<04:08, 82.90s/model]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "Fitting models:  83%|████████▎ | 10/12 [16:30<03:43, 111.59s/model]WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel\n",
      "Using cached StanModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:1 of 100 iterations ended with a divergence (1 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n",
      "Fitting models:  92%|█████████▏| 11/12 [19:49<02:17, 137.67s/model]WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "Fitting models: 100%|██████████| 12/12 [24:43<00:00, 123.62s/model]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_and_evaluate(model: 'StanFactorizer', init_kwargs: dict, X_train, X_val=None):\n",
    "    model_object = model(**init_kwargs)\n",
    " \n",
    "    t0 = time()\n",
    "    model_object.fit(X_train)\n",
    "    fit_time = time()-t0\n",
    "    \n",
    "    train_mae = model_object.mae(X_train)\n",
    "    \n",
    "    if df_val is not None:\n",
    "        val_mae = model_object.mae(X_val)   \n",
    "    else:\n",
    "        val_mae = None\n",
    "        \n",
    "    return model_object, fit_time, train_mae, val_mae\n",
    "\n",
    "def fit_and_evaluate_models(models: Iterable, X_train, X_val=None, candidate_kwargs: dict={},\n",
    "                            static_kwargs: dict={}, verbose=True):\n",
    "        \n",
    "    hist = {'model':[], 'params':[], 'fit_time':[], 'train_mae':[], 'val_mae':[]}\n",
    "    \n",
    "    param_gen = tqdm(ParameterGrid({'model':models, **candidate_kwargs}), \n",
    "                     desc='Fitting models', disable=not verbose, unit='model', position=0)\n",
    "    \n",
    "    for paramdict in param_gen:\n",
    "        model = paramdict.pop('model')\n",
    "        \n",
    "        hist['params'].append(paramdict)\n",
    "        \n",
    "        paramdict = paramdict.copy()\n",
    "        paramdict.update(static_kwargs)\n",
    "\n",
    "        model_object, fit_time, train_mae, val_mae = fit_and_evaluate(\n",
    "            model=model,\n",
    "            init_kwargs=paramdict,\n",
    "            X_train=X_train,\n",
    "            X_val=X_val,\n",
    "        )\n",
    "        \n",
    "        hist['model'].append(model_object)\n",
    "        hist['fit_time'].append(fit_time)\n",
    "        hist['train_mae'].append(train_mae)\n",
    "        hist['val_mae'].append(val_mae)\n",
    "        \n",
    "    return hist\n",
    "    \n",
    "models = [\n",
    "    StanClasses.SimpleFactorizer,\n",
    "    StanClasses.NonNegativeFactorizer,\n",
    "    StanClasses.ARD_Factorizer\n",
    "]\n",
    "\n",
    "init_kwargs = {'n_components':[5,10,15,20]}\n",
    "    \n",
    "static_kwargs = {\n",
    "    'chains':1, \n",
    "    'n_jobs':1, \n",
    "    'iter':1000, \n",
    "    'thin':5, \n",
    "    'control':{'max_treedepth':20}\n",
    "}\n",
    "\n",
    "hist = fit_and_evaluate_models(\n",
    "    models=models,\n",
    "    X_train=df_train,\n",
    "    X_val=df_val,\n",
    "    candidate_kwargs=init_kwargs,\n",
    "    static_kwargs=static_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = pd.DataFrame(hist)\n",
    "df_hist['model'] = df_hist['model'].map(lambda x: type(x).__name__)\n",
    "\n",
    "df_hist.to_pickle('histpickle.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "_ = reload(utils)\n",
    "_ = reload(StanClasses)\n",
    "\n",
    "sm_nmf = StanClasses.NonNegativeFactorizer(10)\n",
    "\n",
    "t0 = time()\n",
    "sm_nmf.fit(df_train, chains=1, n_jobs=1, iter=1000, thin=5, control={'max_treedepth':20})\n",
    "print(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_simple = StanClasses.SimpleFactorizer(10)\n",
    "\n",
    "t0 = time()\n",
    "sm_simple.fit(df_train, chains=1, n_jobs=-1, iter=1000, thin=5, control={'max_treedepth':20})\n",
    "print(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(7,2))\n",
    "plt.grid()\n",
    "sm_simple.ci(show=True, ax=axes, label='Simple', zorder=2)\n",
    "sm_nmf.ci(show=True, ax=axes, label='NMF', zorder=3)\n",
    "plt.xticks(np.arange(20))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm_simple.mae(df_train))\n",
    "print(sm_simple.mae(df_val))\n",
    "print(sm_simple.mae(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = np.linspace(-0.5,4,1000)\n",
    "\n",
    "a = 2\n",
    "b = 4*a\n",
    "y = stats.gamma.pdf(xrange, a=a, scale=1/b)\n",
    "print(a, b)\n",
    "plt.plot(xrange, y)\n",
    "plt.show()\n",
    "\n",
    "a = 1\n",
    "b = 0.08*a\n",
    "y = stats.gamma.pdf(xrange, a=a, scale=1/b)\n",
    "print(a, b)\n",
    "plt.plot(xrange, y)\n",
    "# plt.axvline(((a-1)/b/(a-1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_test_code = utils.get_stan_code('sanity.stan')\n",
    "sm_test = utils.StanModel_cache(sm_test_code, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_test = sm_test.sampling(algorithm=\"Fixed_param\", chains=4, n_jobs=-1, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.674531,0.560879],[-1.82799,0.0132566]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A@A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
