{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import arviz\n",
    "import pystan\n",
    "from scipy import sparse\n",
    "from typing import Iterable, Union, Callable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import altair as alt\n",
    "\n",
    "# Own files\n",
    "import utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have is essentially a matrix, where the each row correspond to a person, and each column correspond to a movie. However, the matrix is very sparse and thus data is stored in sparse format (i.e. specified with indices and the corresponding values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "\n",
    "DATA_DIR = 'ml-100k'\n",
    "SM_NORMALNORMAL_NAME = 'sm_normalnormal.stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(utils)\n",
    "\n",
    "df, _, _ = utils.get_ml100k_data(DATA_DIR, subsample_top_users=150, subsample_top_items=20)\n",
    "\n",
    "# We are not going to use timestamp, therefore drop it\n",
    "df.drop('timestamp', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user ids and item (movie) ids are essentially integer ranges, starting from and 1 to the number of users and items respectively. We don't have the all the unique ids when subsampling users and movies. It becomes problematic ... TODO: Write this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_relabler(df: pd.DataFrame, column: str):\n",
    "    uniques = pd.value_counts(df[column], sort=False).index.values\n",
    "    n_uniques = len(uniques)\n",
    "\n",
    "    # Count from 1 to conform with Stan (Stan counts indexes arrays starting at 1)\n",
    "    num2id = {num_:id_ for num_, id_ in zip(range(1, n_uniques+1), uniques)}\n",
    "    id2num = {id_:num_ for num_, id_ in zip(range(1, n_uniques+1), uniques)}\n",
    "    \n",
    "    df[column] = df[column].map(id2num)\n",
    "    return id2num, num2id\n",
    "\n",
    "df_num = df.copy()\n",
    "user2num, num2user = column_relabler(df_num, 'user_id')\n",
    "item2num, num2item = column_relabler(df_num, 'item_id')\n",
    "\n",
    "# p, q represents shape of the matrix as if it was dense\n",
    "p, q = len(user2num), len(item2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valtest = train_test_split(df_num, test_size=50)\n",
    "df_val, df_test = train_test_split(df_valtest, test_size=25)\n",
    "del df_valtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization \n",
    "Want to factorize the dense matrix $X_{n\\times m} \\approx U_{n\\times k}V_{k\\times m}$, where the subscripts denotes matrix shapes. The $k$ dimension denotes the user specified embedding dimension. We use different probabilistic models for the components. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 \n",
    "Very simple\n",
    "\n",
    "$$ U \\sim N(\\mu_u, \\sigma_u) $$\n",
    "$$ V \\sim N(\\mu_v, \\sigma_v) $$\n",
    "$$ X_{ij}\\sim N(UV_{ij}, \\sigma_x)$$\n",
    "\n",
    "User defined variables:\n",
    "$\\mu_u, \\sigma_u, \\mu_v, \\sigma_v, \\sigma_x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 \n",
    "ARD Model\n",
    "\n",
    "$$ U \\sim N(\\mu_u, \\sigma_u) $$\n",
    "$$ V \\sim N(\\mu_v, \\sigma_v) $$\n",
    "$$ X_{ij}\\sim N(UV_{ij}, \\sigma_x)$$\n",
    "\n",
    "User defined variables:\n",
    "$\\mu_u, \\sigma_u, \\mu_v, \\sigma_v, \\sigma_x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to parse Stan model 'anon_model_ff07baf16aba606c13c9d73e8190e7b9'. Error message:\nSYNTAX ERROR, MESSAGE(S) FROM PARSER:\nVariable \"git\" does not exist.\n error in 'unknown file name' at line 36, column 20\n  -------------------------------------------------\n    34:  model {\n    35:      matrix[p,q] X_hat;\n    36:      int row_idx;git s\n                           ^\n    37:      int col_idx;\n  -------------------------------------------------\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/INF367A/Projects/Project2/utils.py\u001b[0m in \u001b[0;36mStanModel_cache\u001b[0;34m(model_code, model_name, cache_dir, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stan_cache/cached-normalnormal-ff07baf16aba606c13c9d73e8190e7b9.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d92056a65e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msm_normalnormal_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stan_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSM_NORMALNORMAL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msm_normalnormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStanModel_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm_normalnormal_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'normalnormal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/INF367A/Projects/Project2/utils.py\u001b[0m in \u001b[0;36mStanModel_cache\u001b[0;34m(model_code, model_name, cache_dir, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStanModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/INF367A/stanenv/lib/python3.6/site-packages/pystan/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, charset, model_name, model_code, stanc_ret, include_paths, boost_lib, eigen_lib, verbose, obfuscate_model_name, extra_compile_args, allow_undefined, include_dirs, includes)\u001b[0m\n\u001b[1;32m    235\u001b[0m                                          \u001b[0minclude_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                                          \u001b[0mobfuscate_model_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobfuscate_model_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                          allow_undefined=allow_undefined)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstanc_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/INF367A/stanenv/lib/python3.6/site-packages/pystan/api.py\u001b[0m in \u001b[0;36mstanc\u001b[0;34m(file, charset, model_code, model_name, include_paths, verbose, obfuscate_model_name, allow_undefined)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to parse Stan model '{}'. Error message:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# SUCCESS_RC is 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Successfully parsed Stan model '{}'.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to parse Stan model 'anon_model_ff07baf16aba606c13c9d73e8190e7b9'. Error message:\nSYNTAX ERROR, MESSAGE(S) FROM PARSER:\nVariable \"git\" does not exist.\n error in 'unknown file name' at line 36, column 20\n  -------------------------------------------------\n    34:  model {\n    35:      matrix[p,q] X_hat;\n    36:      int row_idx;git s\n                           ^\n    37:      int col_idx;\n  -------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "sm_normalnormal_code = utils.get_stan_code(SM_NORMALNORMAL_NAME)\n",
    "sm_normalnormal = utils.StanModel_cache(sm_normalnormal_code, 'normalnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 43s, sys: 594 ms, total: 3min 44s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_normalnormal = dict(\n",
    "    n_components = 10,\n",
    "    n = X.shape[0],\n",
    "    m = X.shape[1],\n",
    "    p=p,\n",
    "    q=q,\n",
    "    X = X,\n",
    "    mu_u = 1,\n",
    "    sigma_u = 5,\n",
    "    mu_v = 1,\n",
    "    sigma_v = 5,\n",
    "    sigma_x = 1\n",
    ")\n",
    "\n",
    "control = dict(\n",
    "    max_treedepth=20\n",
    ")\n",
    "\n",
    "fit = sm_normalnormal.sampling(data_normalnormal, chains=1, n_jobs=-1, \n",
    "                               iter=4000, control=control, thin=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Us, Vs = fit['U'], fit['V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6207983805594564\n",
      "0.7622367208982618\n",
      "0.8028536168470489\n"
     ]
    }
   ],
   "source": [
    "def ml100k_mae(df: pd.DataFrame, Us: np.ndarray, Vs: np.ndarray):\n",
    "    # Xs is a 3D array\n",
    "    Xs = Us@Vs\n",
    "    \n",
    "    # Offset with -1 because Stan index starts with 1\n",
    "    row_inds = df.user_id-1\n",
    "    col_inds = df.item_id-1\n",
    "    ratings = df.rating.values\n",
    "    \n",
    "    y_preds = np.array([X[row_inds, col_inds] for X in Xs])\n",
    "    errors = np.abs(y_preds - ratings)\n",
    "    \n",
    "    # Mean absolute error\n",
    "    mae = errors.mean()\n",
    "    \n",
    "    return mae\n",
    "    \n",
    "print(ml100k_mae(df_train, Us, Vs))\n",
    "print(ml100k_mae(df_val, Us, Vs))\n",
    "print(ml100k_mae(df_test, Us, Vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CredibleIntervals(Us: np.ndarray, Vs: np.ndarray, scale: float=1, \n",
    "                      boxes: int=20, n: int=1000, p=0.95):\n",
    "    # Xs is a 3D array\n",
    "    Xs = Us@Vs\n",
    "    row_inds, col_inds = np.unravel_index(range(boxes), Xs.shape[1:])\n",
    "    \n",
    "    picks = np.random.randint(0, len(Xs), n)\n",
    "    P = Xs[picks][:,row_inds, col_inds]\n",
    "    \n",
    "    P = np.random.normal(loc=P, scale=scale, size=P.shape)\n",
    "    P.sort(axis=0)\n",
    "    \n",
    "    half_p = (1-p)/2\n",
    "    lb = np.floor((half_p*n)).astype(int)\n",
    "    ub = np.ceil((p+half_p)*n).astype(int)\n",
    "    \n",
    "    return P[lb], P[ub]\n",
    "\n",
    "X__ = CredibleIntervals(Us, Vs, scale=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_test_code = utils.get_stan_code('sanity.stan')\n",
    "sm_test = utils.StanModel_cache(sm_test_code, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_test = sm_test.sampling(algorithm=\"Fixed_param\", chains=4, n_jobs=-1, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.674531,0.560879],[-1.82799,0.0132566]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A@A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
